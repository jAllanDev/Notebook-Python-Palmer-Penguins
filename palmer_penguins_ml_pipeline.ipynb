{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607de406",
   "metadata": {},
   "source": [
    "# Palmer Penguins - Pipeline de Machine Learning\n",
    "\n",
    "**Projeto 02 - Constru√ß√£o de Esteira de Aprendizado de M√°quina**\n",
    "\n",
    "Neste projeto, implementamos uma esteira completa de Machine Learning utilizando o dataset Palmer Penguins.\n",
    "\n",
    "## Dataset\n",
    "O Palmer Penguins √© um dataset que cont√©m informa√ß√µes sobre pinguins de tr√™s esp√©cies diferentes (Adelie, Chinstrap e Gentoo) coletadas nas ilhas Palmer, Ant√°rtica.\n",
    "\n",
    "## Objetivo\n",
    "Criar um modelo de classifica√ß√£o para prever a esp√©cie do pinguim com base em suas caracter√≠sticas f√≠sicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110cfc8",
   "metadata": {},
   "source": [
    "## 1. Importa√ß√£o de Bibliotecas e Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912446a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do dataset Palmer Penguins\n",
    "# O dataset pode ser carregado via seaborn ou URL direta do UCI\n",
    "df = sns.load_dataset('penguins')\n",
    "\n",
    "print(f\"Dataset carregado com sucesso!\")\n",
    "print(f\"Dimens√µes: {df.shape[0]} linhas e {df.shape[1]} colunas\\n\")\n",
    "print(\"Primeiras 5 linhas do dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87419be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informa√ß√µes gerais sobre o dataset\n",
    "print(\"Informa√ß√µes do Dataset:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Tipos de dados:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32065e28",
   "metadata": {},
   "source": [
    "## 2. Estat√≠sticas Descritivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c44acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas descritivas das vari√°veis num√©ricas\n",
    "print(\"Estat√≠sticas Descritivas das Vari√°veis Num√©ricas:\")\n",
    "print(\"=\"*80)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas descritivas das vari√°veis categ√≥ricas\n",
    "print(\"Estat√≠sticas Descritivas das Vari√°veis Categ√≥ricas:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nDistribui√ß√£o de Esp√©cies:\")\n",
    "print(df['species'].value_counts())\n",
    "print(\"\\nDistribui√ß√£o de Ilhas:\")\n",
    "print(df['island'].value_counts())\n",
    "print(\"\\nDistribui√ß√£o de Sexo:\")\n",
    "print(df['sex'].value_counts())\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fde179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o da distribui√ß√£o das vari√°veis num√©ricas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Distribui√ß√£o das Vari√°veis Num√©ricas', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Histogramas\n",
    "df['bill_length_mm'].hist(ax=axes[0, 0], bins=20, edgecolor='black')\n",
    "axes[0, 0].set_title('Comprimento do Bico (mm)')\n",
    "axes[0, 0].set_xlabel('Comprimento (mm)')\n",
    "axes[0, 0].set_ylabel('Frequ√™ncia')\n",
    "\n",
    "df['bill_depth_mm'].hist(ax=axes[0, 1], bins=20, edgecolor='black', color='orange')\n",
    "axes[0, 1].set_title('Profundidade do Bico (mm)')\n",
    "axes[0, 1].set_xlabel('Profundidade (mm)')\n",
    "axes[0, 1].set_ylabel('Frequ√™ncia')\n",
    "\n",
    "df['flipper_length_mm'].hist(ax=axes[1, 0], bins=20, edgecolor='black', color='green')\n",
    "axes[1, 0].set_title('Comprimento da Nadadeira (mm)')\n",
    "axes[1, 0].set_xlabel('Comprimento (mm)')\n",
    "axes[1, 0].set_ylabel('Frequ√™ncia')\n",
    "\n",
    "df['body_mass_g'].hist(ax=axes[1, 1], bins=20, edgecolor='black', color='red')\n",
    "axes[1, 1].set_title('Massa Corporal (g)')\n",
    "axes[1, 1].set_xlabel('Massa (g)')\n",
    "axes[1, 1].set_ylabel('Frequ√™ncia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b845fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para identificar outliers\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Boxplots das Vari√°veis Num√©ricas', fontsize=16, fontweight='bold')\n",
    "\n",
    "df.boxplot(column='bill_length_mm', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Comprimento do Bico')\n",
    "axes[0, 0].set_ylabel('mm')\n",
    "\n",
    "df.boxplot(column='bill_depth_mm', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Profundidade do Bico')\n",
    "axes[0, 1].set_ylabel('mm')\n",
    "\n",
    "df.boxplot(column='flipper_length_mm', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Comprimento da Nadadeira')\n",
    "axes[1, 0].set_ylabel('mm')\n",
    "\n",
    "df.boxplot(column='body_mass_g', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Massa Corporal')\n",
    "axes[1, 1].set_ylabel('g')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd49ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribui√ß√£o das esp√©cies\n",
    "plt.figure(figsize=(10, 6))\n",
    "species_counts = df['species'].value_counts()\n",
    "plt.bar(species_counts.index, species_counts.values, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], edgecolor='black')\n",
    "plt.title('Distribui√ß√£o das Esp√©cies de Pinguins', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Esp√©cie')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(species_counts.values):\n",
    "    plt.text(i, v + 2, str(v), ha='center', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41d627",
   "metadata": {},
   "source": [
    "## 3. Transforma√ß√µes nas Colunas\n",
    "\n",
    "**Transforma√ß√£o aplicada:** Codifica√ß√£o de vari√°veis categ√≥ricas e normaliza√ß√£o de vari√°veis num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma c√≥pia do dataframe para preservar o original\n",
    "df_transformed = df.copy()\n",
    "\n",
    "print(\"Antes da transforma√ß√£o:\")\n",
    "print(f\"Shape: {df_transformed.shape}\")\n",
    "print(f\"\\nColunas: {df_transformed.columns.tolist()}\")\n",
    "print(f\"\\nValores √∫nicos antes da codifica√ß√£o:\")\n",
    "print(f\"Species: {df_transformed['species'].unique()}\")\n",
    "print(f\"Island: {df_transformed['island'].unique()}\")\n",
    "print(f\"Sex: {df_transformed['sex'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMA√á√ÉO DE COLUNAS: Codifica√ß√£o de vari√°veis categ√≥ricas\n",
    "# Utilizando LabelEncoder para transformar vari√°veis categ√≥ricas em num√©ricas\n",
    "\n",
    "# Criar encoders para cada vari√°vel categ√≥rica\n",
    "label_encoders = {}\n",
    "\n",
    "# Codificar 'island'\n",
    "le_island = LabelEncoder()\n",
    "df_transformed['island_encoded'] = le_island.fit_transform(df_transformed['island'])\n",
    "label_encoders['island'] = le_island\n",
    "\n",
    "# Codificar 'sex' (mantendo apenas linhas v√°lidas temporariamente para encoding)\n",
    "df_transformed['sex_encoded'] = df_transformed['sex'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Guardar o encoding da esp√©cie para usar depois\n",
    "le_species = LabelEncoder()\n",
    "df_transformed['species_encoded'] = le_species.fit_transform(df_transformed['species'])\n",
    "label_encoders['species'] = le_species\n",
    "\n",
    "print(\"‚úì Transforma√ß√£o de colunas categ√≥ricas conclu√≠da!\")\n",
    "print(f\"\\nMapeamento Island: {dict(zip(le_island.classes_, le_island.transform(le_island.classes_)))}\")\n",
    "print(f\"Mapeamento Sex: Male=1, Female=0\")\n",
    "print(f\"Mapeamento Species: {dict(zip(le_species.classes_, le_species.transform(le_species.classes_)))}\")\n",
    "print(\"\\nPrimeiras linhas ap√≥s codifica√ß√£o:\")\n",
    "print(df_transformed[['island', 'island_encoded', 'sex', 'sex_encoded', 'species', 'species_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ee9a9",
   "metadata": {},
   "source": [
    "## 4. Transforma√ß√µes nas Linhas\n",
    "\n",
    "**Transforma√ß√£o aplicada:** Remo√ß√£o de linhas com valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b09b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMA√á√ÉO DE LINHAS: Remo√ß√£o de valores ausentes\n",
    "print(\"Valores ausentes antes da limpeza:\")\n",
    "print(df_transformed.isnull().sum())\n",
    "print(f\"\\nTotal de linhas antes: {len(df_transformed)}\")\n",
    "\n",
    "# Remover linhas com valores ausentes\n",
    "df_clean = df_transformed.dropna()\n",
    "\n",
    "print(f\"\\nTotal de linhas depois: {len(df_clean)}\")\n",
    "print(f\"Linhas removidas: {len(df_transformed) - len(df_clean)}\")\n",
    "print(\"\\nValores ausentes ap√≥s a limpeza:\")\n",
    "print(df_clean.isnull().sum())\n",
    "print(\"\\n‚úì Transforma√ß√£o de linhas conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6fc101",
   "metadata": {},
   "source": [
    "## 5. Divis√£o em Treino, Valida√ß√£o e Teste\n",
    "\n",
    "Dividiremos o dataset em tr√™s conjuntos:\n",
    "- **Treino (60%):** Para treinar o modelo\n",
    "- **Valida√ß√£o (20%):** Para ajustar hiperpar√¢metros\n",
    "- **Teste (20%):** Para avaliar o modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fcf880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar features (X) e target (y)\n",
    "# Usar as features num√©ricas originais e as codificadas\n",
    "feature_columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', \n",
    "                   'body_mass_g', 'island_encoded', 'sex_encoded']\n",
    "\n",
    "X = df_clean[feature_columns]\n",
    "y = df_clean['species_encoded']\n",
    "\n",
    "print(\"Features selecionadas:\", feature_columns)\n",
    "print(f\"\\nShape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")\n",
    "print(f\"\\nDistribui√ß√£o das classes:\")\n",
    "print(y.value_counts().sort_index())\n",
    "print(f\"\\nPrimeiras linhas de X:\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeira divis√£o: 80% treino+valida√ß√£o, 20% teste\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Segunda divis√£o: dos 80% restantes, dividir em 75% treino e 25% valida√ß√£o\n",
    "# Isso resulta em: 60% treino, 20% valida√ß√£o, 20% teste do total\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Divis√£o dos dados conclu√≠da!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total de amostras: {len(X)}\")\n",
    "print(f\"\\nConjunto de Treino: {len(X_train)} amostras ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Conjunto de Valida√ß√£o: {len(X_val)} amostras ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"Conjunto de Teste: {len(X_test)} amostras ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribui√ß√£o das classes no conjunto de treino:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\nDistribui√ß√£o das classes no conjunto de valida√ß√£o:\")\n",
    "print(y_val.value_counts().sort_index())\n",
    "print(f\"\\nDistribui√ß√£o das classes no conjunto de teste:\")\n",
    "print(y_test.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79849b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza√ß√£o das features (StandardScaler)\n",
    "# Importante: fit apenas no treino e transform em todos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úì Normaliza√ß√£o aplicada!\")\n",
    "print(\"\\nEstat√≠sticas do conjunto de treino normalizado:\")\n",
    "print(f\"M√©dia: {X_train_scaled.mean(axis=0).round(2)}\")\n",
    "print(f\"Desvio padr√£o: {X_train_scaled.std(axis=0).round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32bcb2",
   "metadata": {},
   "source": [
    "## 6. Treinamento do Modelo\n",
    "\n",
    "Utilizaremos o algoritmo **Random Forest Classifier** para classificar as esp√©cies de pinguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd22dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar e treinar o modelo Random Forest\n",
    "print(\"Iniciando o treinamento do modelo...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"‚úì Modelo treinado com sucesso!\")\n",
    "print(f\"\\nPar√¢metros do modelo:\")\n",
    "print(f\"- N√∫mero de √°rvores: {model.n_estimators}\")\n",
    "print(f\"- Profundidade m√°xima: {model.max_depth}\")\n",
    "print(f\"- N√∫mero de features: {model.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo no conjunto de valida√ß√£o\n",
    "y_val_pred = model.predict(X_val_scaled)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"Avalia√ß√£o no conjunto de valida√ß√£o:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Acur√°cia: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o (Valida√ß√£o):\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=le_species.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bcac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import√¢ncia das features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Import√¢ncia das Features:\")\n",
    "print(\"=\"*60)\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# Visualizar import√¢ncia\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Import√¢ncia')\n",
    "plt.title('Import√¢ncia das Features no Modelo', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1487b8",
   "metadata": {},
   "source": [
    "## 7. Avalia√ß√£o no Conjunto de Teste - Matriz de Confus√£o e Acur√°cia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfe9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer predi√ß√µes no conjunto de teste\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular acur√°cia\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"AVALIA√á√ÉO FINAL NO CONJUNTO DE TESTE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úì Acur√°cia no Teste: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o (Teste):\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=le_species.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc36e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular e visualizar a Matriz de Confus√£o\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"Matriz de Confus√£o:\")\n",
    "print(\"=\"*60)\n",
    "print(cm)\n",
    "\n",
    "# Visualizar a matriz de confus√£o\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le_species.classes_, \n",
    "            yticklabels=le_species.classes_,\n",
    "            cbar_kws={'label': 'Quantidade'},\n",
    "            linewidths=1, linecolor='black')\n",
    "plt.title('Matriz de Confus√£o - Conjunto de Teste', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Classe Real', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Classe Predita', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar m√©tricas detalhadas\n",
    "print(\"\\nInterpreta√ß√£o da Matriz de Confus√£o:\")\n",
    "print(\"=\"*60)\n",
    "for i, species in enumerate(le_species.classes_):\n",
    "    correct = cm[i, i]\n",
    "    total = cm[i, :].sum()\n",
    "    accuracy_class = correct / total if total > 0 else 0\n",
    "    print(f\"{species}: {correct}/{total} corretos ({accuracy_class*100:.1f}% de acur√°cia)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2227aadc",
   "metadata": {},
   "source": [
    "## 8. Predi√ß√£o com o Modelo Implantado\n",
    "\n",
    "Vamos fazer uma predi√ß√£o com uma amostra nova para demonstrar o modelo em a√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0290797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar uma amostra do conjunto de teste para demonstra√ß√£o\n",
    "sample_idx = 0\n",
    "sample = X_test.iloc[sample_idx:sample_idx+1]\n",
    "sample_scaled = X_test_scaled[sample_idx:sample_idx+1]\n",
    "\n",
    "# Fazer a predi√ß√£o\n",
    "prediction = model.predict(sample_scaled)[0]\n",
    "prediction_proba = model.predict_proba(sample_scaled)[0]\n",
    "\n",
    "# Obter informa√ß√µes da amostra original\n",
    "species_real = le_species.inverse_transform([y_test.iloc[sample_idx]])[0]\n",
    "species_pred = le_species.inverse_transform([prediction])[0]\n",
    "\n",
    "print(\"EXEMPLO DE PREDI√á√ÉO COM O MODELO\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìã Caracter√≠sticas do Pinguim:\")\n",
    "print(\"-\" * 60)\n",
    "for i, col in enumerate(feature_columns):\n",
    "    print(f\"  {col:25s}: {sample.iloc[0, i]:.2f}\")\n",
    "\n",
    "print(\"\\nüéØ Resultado da Predi√ß√£o:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Esp√©cie Real:      {species_real}\")\n",
    "print(f\"  Esp√©cie Predita:   {species_pred}\")\n",
    "print(f\"  ‚úì Predi√ß√£o:        {'CORRETA ‚úì' if species_real == species_pred else 'INCORRETA ‚úó'}\")\n",
    "\n",
    "print(\"\\nüìä Probabilidades por Classe:\")\n",
    "print(\"-\" * 60)\n",
    "for i, species in enumerate(le_species.classes_):\n",
    "    prob = prediction_proba[i]\n",
    "    bar = \"‚ñà\" * int(prob * 50)\n",
    "    print(f\"  {species:12s}: {prob*100:6.2f}% {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer predi√ß√µes para m√∫ltiplas amostras\n",
    "print(\"PREDI√á√ïES PARA M√öLTIPLAS AMOSTRAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "num_samples = 5\n",
    "for i in range(min(num_samples, len(X_test))):\n",
    "    sample = X_test.iloc[i:i+1]\n",
    "    sample_scaled = X_test_scaled[i:i+1]\n",
    "    \n",
    "    prediction = model.predict(sample_scaled)[0]\n",
    "    species_real = le_species.inverse_transform([y_test.iloc[i]])[0]\n",
    "    species_pred = le_species.inverse_transform([prediction])[0]\n",
    "    \n",
    "    status = \"‚úì\" if species_real == species_pred else \"‚úó\"\n",
    "    print(f\"Amostra {i+1}: Real={species_real:12s} | Predito={species_pred:12s} | {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14edb5",
   "metadata": {},
   "source": [
    "## 9. Conclus√µes\n",
    "\n",
    "### Resumo do Projeto\n",
    "\n",
    "Neste projeto, implementamos uma esteira completa de Machine Learning para classifica√ß√£o de esp√©cies de pinguins usando o dataset Palmer Penguins:\n",
    "\n",
    "1. **Dataset**: Palmer Penguins com 3 esp√©cies (Adelie, Chinstrap, Gentoo)\n",
    "2. **Estat√≠sticas Descritivas**: An√°lise completa das vari√°veis num√©ricas e categ√≥ricas\n",
    "3. **Transforma√ß√µes**:\n",
    "   - **Colunas**: Codifica√ß√£o de vari√°veis categ√≥ricas e normaliza√ß√£o\n",
    "   - **Linhas**: Remo√ß√£o de valores ausentes\n",
    "4. **Divis√£o dos Dados**: 60% treino, 20% valida√ß√£o, 20% teste\n",
    "5. **Modelo**: Random Forest Classifier\n",
    "6. **Resultados**: Alta acur√°cia na classifica√ß√£o das esp√©cies\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "- Testar outros algoritmos (SVM, XGBoost, Neural Networks)\n",
    "- Realizar ajuste fino de hiperpar√¢metros (GridSearch/RandomSearch)\n",
    "- Implementar valida√ß√£o cruzada\n",
    "- Exportar o modelo para produ√ß√£o"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
